{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "似乎抓到一些不該抓的\n",
        "Counsel: 95個 \n",
        "Judges: 94個 (P471沒有)\n",
        "Opinion by: 95個\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kndgiv96am3L",
        "outputId": "cc20dd8f-97e8-4230-af97-02a8085a94d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "完成：C:\\Users\\User\\Dropbox\\textmining1\\opinion\\opinion_100_test.csv\n",
            "Counsel 數量: 95\n",
            "Judges 數量: 92\n",
            "Opinion by 數量: 95\n"
          ]
        }
      ],
      "source": [
        "# Explain\n",
        "import fitz\n",
        "import re\n",
        "import csv\n",
        "\n",
        "pdf_file_path = r'C:\\Users\\User\\Dropbox\\textmining1\\PDF\\Files (100).PDF'\n",
        "csv_file_path = r'C:\\Users\\User\\Dropbox\\textmining1\\opinion\\opinion_100_test.csv'\n",
        "\n",
        "\n",
        "pattern = r'(Counsel:.*?|Judges:.*?(?=Opinion by:)|Opinion by:.*?)((?=Counsel:)|(?=Judges:)|(?=Opinion by:)|(?=Opinion)|$)'\n",
        "\n",
        "# \" (Counsel:.*?|Judges:.*?(?=Opinion by:)|Opinion by:.*?) \"  :\n",
        "# capture content of \" Counsel: \", \" Judges: \" 到 \"Opinion by:\" or \"Opinion\"\n",
        "\n",
        "# \" ((?=Counsel:)|(?=Judges:)|(?=Opinion by:)|(?=Opinion)|$) \" :\n",
        "# capture the type of the match (\"Counsel:\", \"Judges:\", \"Opinion by:\", \"Opinion\", or the end of the string).\n",
        "\n",
        "\n",
        "def find_page_num(text, match_start, page_delimiters):\n",
        "\n",
        "#找出匹配文本再PDF的頁碼. Text(整個PDF文本內容) . match_start(當前匹配文本起始位置)\n",
        "# page_delimiters(包含每頁結尾在text中的列表) 將每頁文本加入all_text並記錄長度, 每個元素代表文本結束的位置\n",
        "    for i, delimiter in enumerate(page_delimiters): # i為當前頁碼索引 從0開始\n",
        "        if match_start < delimiter: #檢查match_start是否小於delimiter  , 小於代表匹配文本位於這一頁或之前的頁面\n",
        "            return i #頁碼通常從1開始, 所以後續都會對這個索引 + 1\n",
        "    return len(page_delimiters) # 表示匹配文本位於文檔最後一頁\n",
        "\n",
        "# 加入計數器\n",
        "counsel_count = 0\n",
        "judges_count = 0\n",
        "opinion_by_count = 0\n",
        "\n",
        "with fitz.open(pdf_file_path) as doc:\n",
        "    all_text = \"\" #儲存整個文本內容\n",
        "    page_delimiters = [] #儲存每頁文本結束的列表\n",
        "\n",
        "    for page_num in range(len(doc)): #閱讀文本每一頁 . len(doc):總頁數\n",
        "        page = doc.load_page(page_num) #載入當前頁\n",
        "        page_text = page.get_text(\"text\")  # 獲取當前頁的文本\n",
        "        all_text += page.get_text(\"text\") + \"\\f\" #從當前頁提取文本並添加到all_text中 # 使用分頁符號 \"\\f\" 作為分頁標記\n",
        "        page_delimiters.append(len(all_text))  # 在page_delimiters列表添加累積文本長度,也就是當前頁結束位置, 紀錄每頁結束的位置.\n",
        "        # 在每段文本前加上頁碼標記\n",
        "        formatted_page_text = f'頁碼 {page_num + 1}:\\n{page_text}'\n",
        "    # 移除包含 \"Page \\d+ of \\d+\" 的字樣\n",
        "    all_text = re.sub(r'Page \\d+ of \\d+', '', all_text)\n",
        "\n",
        "# re.sub 查找和替換 符合正則表達式的字串, ''表示將匹配內容刪除\n",
        "# \\d+ 數字 . Page和of 為單詞 . 表 刪除 ex Page 23 of 456 將其中all_text中刪除\n",
        "\n",
        "    # 移除其他不重要的字樣\n",
        "    all_text = re.sub(r'\\d+ Cal\\..*?\\*{1,4}\\d+; (?:\\d{4} )?Cal\\..*?\\*{1,4}\\d+', '', all_text)\n",
        "\n",
        "# Cal\\. = Cal. \" .*? \" 非貪婪匹配任所有字符直到遇到後面的模式 \"\\*{1,4}\" 匹配1~4個'*' ;匹配分號\n",
        "# (?:\\d{4} ) 匹配四位數字後跟一個空格 , Cal\\..*?\\*{1,4}\\d+ 同上 匹配Cal. 後面的文字,星號,數字\n",
        "\n",
        "    with open(csv_file_path, 'w', encoding='utf-8', newline='') as csv_file:\n",
        "      #確保文件使用utf-8編碼, newline=''為了避免在不同操作系統寫入時產生新行問題\n",
        "        csv_writer = csv.writer(csv_file) # 創建CSV寫入器,將數據輸入\n",
        "        csv_writer.writerow(['頁碼', '內容類型', '內容']) #將標題寫入\n",
        "\n",
        "        matches = re.finditer(pattern, all_text, re.DOTALL) # find all occourance of pattern in 'text'\n",
        "        for match in matches: #loop initiate matches from re.finditer\n",
        "            match_content = match.group(1).strip() # 提取第一個匹配組內容,去除首尾空格\n",
        "            match_type = match.group(2).strip()  # 提取第二個匹配組內容,去除首尾空格\n",
        "            match_page = find_page_num(all_text, match.start(), page_delimiters)\n",
        "            # 調用find_page_num函數確定匹配內容所在頁碼,將這些資訊寫入CSV\n",
        "\n",
        "            if 'Counsel:' in match_content:\n",
        "                csv_writer.writerow([match_page + 1, 'Counsel', match_content])\n",
        "                counsel_count += 1\n",
        "            elif 'Judges:' in match_content:\n",
        "                csv_writer.writerow([match_page + 1, 'Judges', match_content])\n",
        "                judges_count += 1\n",
        "            elif 'Opinion by:' in match_content:\n",
        "                csv_writer.writerow([match_page + 1, 'Opinion by', match_content])\n",
        "                opinion_by_count += 1\n",
        "\n",
        "print(f\"完成：{csv_file_path}\")\n",
        "print(f\"Counsel 數量: {counsel_count}\")\n",
        "print(f\"Judges 數量: {judges_count}\")\n",
        "print(f\"Opinion by 數量: {opinion_by_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "完成：C:\\Users\\User\\Dropbox\\textmining1\\opinion\\opinion_35_Test2.csv\n",
            "Counsel 數量: 34\n",
            "Judges 數量: 35\n",
            "Opinion by 數量: 34\n"
          ]
        }
      ],
      "source": [
        "# 接近完整 FN還在\n",
        "import fitz  # PyMuPDF\n",
        "import re\n",
        "import csv\n",
        "\n",
        "pdf_file_path = r'C:\\Users\\User\\Dropbox\\textmining1\\PDF\\Files (35).PDF'\n",
        "csv_file_path = r'C:\\Users\\User\\Dropbox\\textmining1\\opinion\\opinion_35_Test2.csv'\n",
        "\n",
        "# 更新後的正則表達式，確保遇到下一個標記或\"Opinion\"時停止\n",
        "pattern = r'(Counsel:.*?)(?=Counsel:|Judges:|Opinion by:|Opinion|$)|(Judges:.*?)(?=Counsel:|Judges:|Opinion by:|Opinion|$)|(Opinion by:.*?)(?=Counsel:|Judges:|Opinion by:|Opinion|$)'\n",
        "\n",
        "def find_page_num(text, match_start, page_delimiters):\n",
        "    for i, delimiter in enumerate(page_delimiters):\n",
        "        if match_start < delimiter:\n",
        "            return i\n",
        "    return len(page_delimiters)\n",
        "\n",
        "counsel_count = 0\n",
        "judges_count = 0\n",
        "opinion_by_count = 0\n",
        "\n",
        "with fitz.open(pdf_file_path) as doc:\n",
        "    all_text = \"\"\n",
        "    page_delimiters = []\n",
        "\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "        page_text = page.get_text(\"text\")\n",
        "        all_text += page_text + \"\\f\"\n",
        "        page_delimiters.append(len(all_text))\n",
        "\n",
        "    # 移除頁碼和案例引用\n",
        "    all_text = re.sub(r'Page \\d+ of \\d+', '', all_text)\n",
        "    all_text = re.sub(r'\\d+ Cal\\..*?\\*{1,4}\\d+; (?:\\d{4} )?Cal\\..*?\\*{1,4}\\d+', '', all_text)\n",
        "\n",
        "    with open(csv_file_path, 'w', encoding='utf-8', newline='') as csv_file:\n",
        "        csv_writer = csv.writer(csv_file)\n",
        "        csv_writer.writerow(['頁碼', '內容類型', '內容'])\n",
        "\n",
        "        matches = re.finditer(pattern, all_text, re.DOTALL)\n",
        "        for match in matches:\n",
        "            for group_num in range(1, 4):\n",
        "                if match.group(group_num):\n",
        "                    match_content = match.group(group_num).strip()\n",
        "                    match_page = find_page_num(all_text, match.start(group_num), page_delimiters)\n",
        "                    content_type = 'Counsel' if group_num == 1 else 'Judges' if group_num == 2 else 'Opinion by'\n",
        "                    csv_writer.writerow([match_page + 1, content_type, match_content])\n",
        "                    if content_type == 'Counsel':\n",
        "                        counsel_count += 1\n",
        "                    elif content_type == 'Judges':\n",
        "                        judges_count += 1\n",
        "                    elif content_type == 'Opinion by':\n",
        "                        opinion_by_count += 1\n",
        "                    break\n",
        "\n",
        "print(f\"完成：{csv_file_path}\")\n",
        "print(f\"Counsel 數量: {counsel_count}\")\n",
        "print(f\"Judges 數量: {judges_count}\")\n",
        "print(f\"Opinion by 數量: {opinion_by_count}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
